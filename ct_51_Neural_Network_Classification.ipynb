{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ct 51 Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "CO CST IMPLEMENTATION OF NEURAL NETWORK\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2411329c-4885-443f-b647-71ea974b8fa1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "876be73a-bafd-4851-fa66-6a1fb8609f50"
      },
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e418835-8752-40ca-8d04-a3c9de130ef1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 5f925bd1-0846-42e2-8873-fe19630ca670.jpg\n",
            "'AITR - Code Chef Ids of 3rd Year.xlsx'\n",
            "'Certificate for Samruddhi khandelwal for \"Webinar - \"Demystifying Dat...\".pdf'\n",
            "'Certificate for Samruddhi khandelwal for \"Webinar Feedback Form\" (1).pdf'\n",
            "'Certificate for Samruddhi khandelwal for \"Webinar Feedback Form\" (2).pdf'\n",
            "'Certificate for Samruddhi khandelwal for \"Webinar Feedback Form\".pdf'\n",
            " Classroom\n",
            "'Class Wise Due Template-1.pdf'\n",
            "'Class Wise Due Template.pdf'\n",
            "'Colab Notebooks'\n",
            "'CT- V Sem- Practical Exam. TT (Jul-Dec 2021).jpg'\n",
            "'dataset1 (1).csv'\n",
            " diabetes.csv\n",
            "'G5- online railway reservation system.doc'\n",
            " IMG_20210809_225459.jpg\n",
            " Introduction_to_Machine_Learning_Lec1-converted.gdoc\n",
            "'Iwt assignment'\n",
            " knapsack.pdf\n",
            "'lab work'\n",
            " laptops.csv.gsheet\n",
            "'linux lab'\n",
            "'Linux OS & Installation.pptx'\n",
            "'ML lab'\n",
            " Parent_AFD_2297252_29122020202911430.pdf\n",
            "'Quick sort.pdf'\n",
            "'Samruddhi khandelwal CT51 assignment 2.docx'\n",
            "'samruddhi khandelwal.pdf'\n",
            "'Samruddhi khandelwal.pdf'\n",
            " Scanned_20200916-1257.pdf\n",
            "'Scanned_20200916-1303.pdf physics... .pdf'\n",
            " Screenshot_2021-07-24-13-34-37-368_com.cisco.webex.meetings.jpg\n",
            " Screenshot_2021-08-09-23-02-21-530_com.miui.gallery.jpg\n",
            "'Share DS File-CT-48.docx'\n",
            "'Sprint 1.gdoc'\n",
            " Student_AFD_2297252_29122020202911293.pdf\n",
            "'Student_CS_MADHYA PRADESH2297252.pdf'\n",
            "'Students Internship documents format.rar'\n",
            "'TOC_Practical_assessment_format (1).gdoc'\n",
            " TOC_Practical_assessment_format.gdoc\n",
            "'Untitled folder'\n",
            "'Untitled presentation.gslides'\n",
            " vcards_20200706_125433.vcf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "b19a4386-af4f-40ac-ac65-f6541fb12a33"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f47ee437-4b4a-4964-8eb1-fa1844a05e9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f47ee437-4b4a-4964-8eb1-fa1844a05e9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f47ee437-4b4a-4964-8eb1-fa1844a05e9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f47ee437-4b4a-4964-8eb1-fa1844a05e9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "59a979a5-3e88-4bbd-ff87-e6b6f4fec2a8"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "cf1438dc-2c67-4dc4-e776-83d43f55705b"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "6b3fd949-3e75-42d3-a877-8a44b19b9161"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "bb35c66e-1d6c-4045-af43-662b24058f8a"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "407c29d6-45cc-4207-fa29-4d797248bcd4"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "0547f1f3-5c68-4721-b5bc-0f56b4a8ee90"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNfmvbMOXeku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cf79a9-2d8d-42c4-e855-ade422a5a35c"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(12, activation='tanh'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 24)                216       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                500       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                252       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,090\n",
            "Trainable params: 1,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "219cad1e-7649-4d00-d160-3c8821c69f94"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=7,  epochs=650, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6569e-05 - accuracy: 1.0000 - val_loss: 4.1672 - val_accuracy: 0.7154\n",
            "Epoch 2/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6572e-05 - accuracy: 1.0000 - val_loss: 4.1672 - val_accuracy: 0.7154\n",
            "Epoch 3/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6555e-05 - accuracy: 1.0000 - val_loss: 4.1672 - val_accuracy: 0.7154\n",
            "Epoch 4/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6568e-05 - accuracy: 1.0000 - val_loss: 4.1672 - val_accuracy: 0.7154\n",
            "Epoch 5/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6553e-05 - accuracy: 1.0000 - val_loss: 4.1672 - val_accuracy: 0.7154\n",
            "Epoch 6/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6553e-05 - accuracy: 1.0000 - val_loss: 4.1672 - val_accuracy: 0.7154\n",
            "Epoch 7/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6569e-05 - accuracy: 1.0000 - val_loss: 4.1673 - val_accuracy: 0.7154\n",
            "Epoch 8/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6564e-05 - accuracy: 1.0000 - val_loss: 4.1673 - val_accuracy: 0.7154\n",
            "Epoch 9/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6560e-05 - accuracy: 1.0000 - val_loss: 4.1673 - val_accuracy: 0.7154\n",
            "Epoch 10/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6550e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 11/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6548e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 12/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6553e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 13/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6547e-05 - accuracy: 1.0000 - val_loss: 4.1673 - val_accuracy: 0.7154\n",
            "Epoch 14/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6548e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 15/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6538e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 16/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6541e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 17/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6539e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 18/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6539e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 19/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6524e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 20/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6533e-05 - accuracy: 1.0000 - val_loss: 4.1674 - val_accuracy: 0.7154\n",
            "Epoch 21/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6525e-05 - accuracy: 1.0000 - val_loss: 4.1675 - val_accuracy: 0.7154\n",
            "Epoch 22/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6527e-05 - accuracy: 1.0000 - val_loss: 4.1675 - val_accuracy: 0.7154\n",
            "Epoch 23/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6522e-05 - accuracy: 1.0000 - val_loss: 4.1675 - val_accuracy: 0.7154\n",
            "Epoch 24/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6515e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 25/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6546e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 26/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6537e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 27/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6523e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 28/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6517e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 29/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6524e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 30/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6520e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 31/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6516e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 32/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6507e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 33/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6506e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 34/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6522e-05 - accuracy: 1.0000 - val_loss: 4.1675 - val_accuracy: 0.7154\n",
            "Epoch 35/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6506e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 36/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6500e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 37/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6504e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 38/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6498e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 39/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6501e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 40/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6490e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 41/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6495e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 42/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6493e-05 - accuracy: 1.0000 - val_loss: 4.1677 - val_accuracy: 0.7154\n",
            "Epoch 43/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6484e-05 - accuracy: 1.0000 - val_loss: 4.1677 - val_accuracy: 0.7154\n",
            "Epoch 44/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6479e-05 - accuracy: 1.0000 - val_loss: 4.1676 - val_accuracy: 0.7154\n",
            "Epoch 45/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6493e-05 - accuracy: 1.0000 - val_loss: 4.1677 - val_accuracy: 0.7154\n",
            "Epoch 46/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6503e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 47/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6479e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 48/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6472e-05 - accuracy: 1.0000 - val_loss: 4.1677 - val_accuracy: 0.7154\n",
            "Epoch 49/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6478e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 50/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6468e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 51/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6472e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 52/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6456e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 53/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6469e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 54/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6467e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 55/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6467e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 56/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6462e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 57/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6459e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 58/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6456e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 59/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6465e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 60/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6451e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 61/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6453e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 62/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6450e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 63/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6440e-05 - accuracy: 1.0000 - val_loss: 4.1677 - val_accuracy: 0.7154\n",
            "Epoch 64/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6456e-05 - accuracy: 1.0000 - val_loss: 4.1677 - val_accuracy: 0.7154\n",
            "Epoch 65/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6444e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 66/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6448e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 67/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6448e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 68/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6440e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 69/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6436e-05 - accuracy: 1.0000 - val_loss: 4.1680 - val_accuracy: 0.7154\n",
            "Epoch 70/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6455e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 71/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6440e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 72/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6431e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 73/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6439e-05 - accuracy: 1.0000 - val_loss: 4.1680 - val_accuracy: 0.7154\n",
            "Epoch 74/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6430e-05 - accuracy: 1.0000 - val_loss: 4.1680 - val_accuracy: 0.7154\n",
            "Epoch 75/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6431e-05 - accuracy: 1.0000 - val_loss: 4.1678 - val_accuracy: 0.7154\n",
            "Epoch 76/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6426e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 77/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6416e-05 - accuracy: 1.0000 - val_loss: 4.1679 - val_accuracy: 0.7154\n",
            "Epoch 78/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6436e-05 - accuracy: 1.0000 - val_loss: 4.1680 - val_accuracy: 0.7154\n",
            "Epoch 79/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6411e-05 - accuracy: 1.0000 - val_loss: 4.1680 - val_accuracy: 0.7154\n",
            "Epoch 80/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6420e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 81/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6415e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 82/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6410e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 83/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6420e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 84/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6409e-05 - accuracy: 1.0000 - val_loss: 4.1680 - val_accuracy: 0.7154\n",
            "Epoch 85/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6404e-05 - accuracy: 1.0000 - val_loss: 4.1680 - val_accuracy: 0.7154\n",
            "Epoch 86/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6406e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 87/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6398e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 88/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6385e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 89/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6399e-05 - accuracy: 1.0000 - val_loss: 4.1682 - val_accuracy: 0.7154\n",
            "Epoch 90/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6399e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 91/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6400e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 92/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6382e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 93/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6393e-05 - accuracy: 1.0000 - val_loss: 4.1682 - val_accuracy: 0.7154\n",
            "Epoch 94/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6391e-05 - accuracy: 1.0000 - val_loss: 4.1682 - val_accuracy: 0.7154\n",
            "Epoch 95/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6389e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 96/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6379e-05 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.7154\n",
            "Epoch 97/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6384e-05 - accuracy: 1.0000 - val_loss: 4.1682 - val_accuracy: 0.7154\n",
            "Epoch 98/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6382e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 99/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6377e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 100/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6376e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 101/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6372e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 102/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6375e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 103/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6387e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 104/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6369e-05 - accuracy: 1.0000 - val_loss: 4.1684 - val_accuracy: 0.7154\n",
            "Epoch 105/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6365e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 106/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6371e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 107/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6360e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 108/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6361e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 109/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6364e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 110/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6348e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 111/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6361e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 112/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6349e-05 - accuracy: 1.0000 - val_loss: 4.1684 - val_accuracy: 0.7154\n",
            "Epoch 113/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6343e-05 - accuracy: 1.0000 - val_loss: 4.1683 - val_accuracy: 0.7154\n",
            "Epoch 114/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6356e-05 - accuracy: 1.0000 - val_loss: 4.1684 - val_accuracy: 0.7154\n",
            "Epoch 115/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6353e-05 - accuracy: 1.0000 - val_loss: 4.1684 - val_accuracy: 0.7154\n",
            "Epoch 116/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6351e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 117/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6337e-05 - accuracy: 1.0000 - val_loss: 4.1684 - val_accuracy: 0.7154\n",
            "Epoch 118/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6352e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 119/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6336e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 120/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6348e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 121/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6334e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 122/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6332e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 123/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6332e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 124/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6330e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 125/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6330e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 126/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6322e-05 - accuracy: 1.0000 - val_loss: 4.1684 - val_accuracy: 0.7154\n",
            "Epoch 127/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6338e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 128/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6317e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 129/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6327e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 130/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6314e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 131/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6314e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 132/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6319e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 133/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6317e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 134/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6317e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 135/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6301e-05 - accuracy: 1.0000 - val_loss: 4.1685 - val_accuracy: 0.7154\n",
            "Epoch 136/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6308e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 137/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6299e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 138/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6302e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 139/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6305e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 140/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6298e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 141/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6293e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 142/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6295e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 143/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6288e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 144/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6302e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 145/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6299e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 146/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6278e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 147/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6283e-05 - accuracy: 1.0000 - val_loss: 4.1686 - val_accuracy: 0.7154\n",
            "Epoch 148/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6289e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 149/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6276e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 150/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6271e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 151/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6284e-05 - accuracy: 1.0000 - val_loss: 4.1687 - val_accuracy: 0.7154\n",
            "Epoch 152/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6274e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.7154\n",
            "Epoch 153/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6269e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.7154\n",
            "Epoch 154/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6270e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.7154\n",
            "Epoch 155/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6268e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.7154\n",
            "Epoch 156/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6271e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.7154\n",
            "Epoch 157/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6258e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 158/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6265e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 159/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6252e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 160/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6263e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 161/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6248e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.7154\n",
            "Epoch 162/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6261e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 163/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6246e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.7154\n",
            "Epoch 164/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6256e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.7154\n",
            "Epoch 165/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6246e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 166/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6254e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 167/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6253e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 168/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6238e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 169/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6238e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 170/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6236e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 171/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6243e-05 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.7154\n",
            "Epoch 172/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6238e-05 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.7154\n",
            "Epoch 173/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6232e-05 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.7154\n",
            "Epoch 174/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6238e-05 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.7154\n",
            "Epoch 175/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6231e-05 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.7154\n",
            "Epoch 176/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6235e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 177/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6225e-05 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.7154\n",
            "Epoch 178/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6228e-05 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.7154\n",
            "Epoch 179/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6224e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 180/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6225e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 181/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6214e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 182/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6213e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 183/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6216e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 184/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6195e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 185/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6209e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 186/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6208e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 187/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6210e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 188/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6202e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 189/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6238e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 190/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6210e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 191/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6198e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 192/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6198e-05 - accuracy: 1.0000 - val_loss: 4.1693 - val_accuracy: 0.7154\n",
            "Epoch 193/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6193e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 194/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6197e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 195/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6210e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 196/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6199e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 197/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6193e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 198/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6195e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 199/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6176e-05 - accuracy: 1.0000 - val_loss: 4.1689 - val_accuracy: 0.7154\n",
            "Epoch 200/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6208e-05 - accuracy: 1.0000 - val_loss: 4.1690 - val_accuracy: 0.7154\n",
            "Epoch 201/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6195e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 202/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6181e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 203/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6184e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 204/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6178e-05 - accuracy: 1.0000 - val_loss: 4.1691 - val_accuracy: 0.7154\n",
            "Epoch 205/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6172e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 206/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6170e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 207/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6169e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 208/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6166e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 209/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6166e-05 - accuracy: 1.0000 - val_loss: 4.1692 - val_accuracy: 0.7154\n",
            "Epoch 210/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6159e-05 - accuracy: 1.0000 - val_loss: 4.1693 - val_accuracy: 0.7154\n",
            "Epoch 211/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6166e-05 - accuracy: 1.0000 - val_loss: 4.1693 - val_accuracy: 0.7154\n",
            "Epoch 212/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6158e-05 - accuracy: 1.0000 - val_loss: 4.1693 - val_accuracy: 0.7154\n",
            "Epoch 213/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6165e-05 - accuracy: 1.0000 - val_loss: 4.1694 - val_accuracy: 0.7154\n",
            "Epoch 214/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6158e-05 - accuracy: 1.0000 - val_loss: 4.1694 - val_accuracy: 0.7154\n",
            "Epoch 215/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6156e-05 - accuracy: 1.0000 - val_loss: 4.1695 - val_accuracy: 0.7154\n",
            "Epoch 216/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6155e-05 - accuracy: 1.0000 - val_loss: 4.1694 - val_accuracy: 0.7154\n",
            "Epoch 217/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6145e-05 - accuracy: 1.0000 - val_loss: 4.1696 - val_accuracy: 0.7154\n",
            "Epoch 218/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6148e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 219/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6146e-05 - accuracy: 1.0000 - val_loss: 4.1696 - val_accuracy: 0.7154\n",
            "Epoch 220/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6144e-05 - accuracy: 1.0000 - val_loss: 4.1696 - val_accuracy: 0.7154\n",
            "Epoch 221/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6152e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 222/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6135e-05 - accuracy: 1.0000 - val_loss: 4.1696 - val_accuracy: 0.7154\n",
            "Epoch 223/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6134e-05 - accuracy: 1.0000 - val_loss: 4.1696 - val_accuracy: 0.7154\n",
            "Epoch 224/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6135e-05 - accuracy: 1.0000 - val_loss: 4.1696 - val_accuracy: 0.7154\n",
            "Epoch 225/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6129e-05 - accuracy: 1.0000 - val_loss: 4.1696 - val_accuracy: 0.7154\n",
            "Epoch 226/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6133e-05 - accuracy: 1.0000 - val_loss: 4.1696 - val_accuracy: 0.7154\n",
            "Epoch 227/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6126e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 228/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6130e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 229/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6125e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 230/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6135e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 231/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6119e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 232/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6119e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 233/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6115e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 234/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6105e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 235/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6106e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 236/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6124e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 237/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6121e-05 - accuracy: 1.0000 - val_loss: 4.1697 - val_accuracy: 0.7154\n",
            "Epoch 238/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6111e-05 - accuracy: 1.0000 - val_loss: 4.1698 - val_accuracy: 0.7154\n",
            "Epoch 239/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6106e-05 - accuracy: 1.0000 - val_loss: 4.1698 - val_accuracy: 0.7154\n",
            "Epoch 240/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6104e-05 - accuracy: 1.0000 - val_loss: 4.1698 - val_accuracy: 0.7154\n",
            "Epoch 241/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6100e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 242/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6105e-05 - accuracy: 1.0000 - val_loss: 4.1698 - val_accuracy: 0.7154\n",
            "Epoch 243/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6101e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 244/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6093e-05 - accuracy: 1.0000 - val_loss: 4.1698 - val_accuracy: 0.7154\n",
            "Epoch 245/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6096e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 246/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6085e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 247/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6097e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 248/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6074e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 249/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6086e-05 - accuracy: 1.0000 - val_loss: 4.1700 - val_accuracy: 0.7154\n",
            "Epoch 250/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6085e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 251/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6082e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 252/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6074e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 253/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6080e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 254/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6074e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 255/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6077e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 256/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6069e-05 - accuracy: 1.0000 - val_loss: 4.1699 - val_accuracy: 0.7154\n",
            "Epoch 257/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6085e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 258/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6081e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 259/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6085e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 260/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6077e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 261/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6067e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 262/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6062e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 263/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6060e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 264/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6060e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 265/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6060e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 266/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6048e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 267/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6055e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 268/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6051e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 269/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6055e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 270/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6056e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 271/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6048e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 272/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6042e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 273/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6044e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 274/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6035e-05 - accuracy: 1.0000 - val_loss: 4.1701 - val_accuracy: 0.7154\n",
            "Epoch 275/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6042e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 276/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6037e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 277/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6037e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 278/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6032e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 279/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6031e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 280/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6025e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 281/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6028e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 282/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6016e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 283/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6025e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 284/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6025e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 285/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6017e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 286/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6015e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 287/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6007e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 288/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6028e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 289/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5999e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 290/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6021e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 291/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6000e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 292/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.6005e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 293/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5995e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 294/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5990e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 295/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6008e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 296/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5994e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 297/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5993e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 298/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5991e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 299/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5994e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 300/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5981e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 301/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5989e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 302/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5987e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 303/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5978e-05 - accuracy: 1.0000 - val_loss: 4.1704 - val_accuracy: 0.7154\n",
            "Epoch 304/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5989e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 305/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5996e-05 - accuracy: 1.0000 - val_loss: 4.1702 - val_accuracy: 0.7154\n",
            "Epoch 306/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5986e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 307/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.6001e-05 - accuracy: 1.0000 - val_loss: 4.1703 - val_accuracy: 0.7154\n",
            "Epoch 308/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5976e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 309/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5987e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 310/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5971e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 311/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5967e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 312/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5982e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 313/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5968e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 314/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5966e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 315/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5960e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 316/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5960e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 317/650\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 7.5960e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 318/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5957e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 319/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5954e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 320/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5954e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 321/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5952e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 322/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5951e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 323/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5947e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 324/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5943e-05 - accuracy: 1.0000 - val_loss: 4.1705 - val_accuracy: 0.7154\n",
            "Epoch 325/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5938e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 326/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5932e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 327/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5936e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 328/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5928e-05 - accuracy: 1.0000 - val_loss: 4.1707 - val_accuracy: 0.7154\n",
            "Epoch 329/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5936e-05 - accuracy: 1.0000 - val_loss: 4.1706 - val_accuracy: 0.7154\n",
            "Epoch 330/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5939e-05 - accuracy: 1.0000 - val_loss: 4.1707 - val_accuracy: 0.7154\n",
            "Epoch 331/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5930e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.7154\n",
            "Epoch 332/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5933e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.7154\n",
            "Epoch 333/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5916e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.7154\n",
            "Epoch 334/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5932e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.7154\n",
            "Epoch 335/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5919e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.7154\n",
            "Epoch 336/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5919e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.7154\n",
            "Epoch 337/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5921e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.7154\n",
            "Epoch 338/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5914e-05 - accuracy: 1.0000 - val_loss: 4.1708 - val_accuracy: 0.7154\n",
            "Epoch 339/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5917e-05 - accuracy: 1.0000 - val_loss: 4.1709 - val_accuracy: 0.7154\n",
            "Epoch 340/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5916e-05 - accuracy: 1.0000 - val_loss: 4.1709 - val_accuracy: 0.7154\n",
            "Epoch 341/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5903e-05 - accuracy: 1.0000 - val_loss: 4.1709 - val_accuracy: 0.7154\n",
            "Epoch 342/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5908e-05 - accuracy: 1.0000 - val_loss: 4.1710 - val_accuracy: 0.7154\n",
            "Epoch 343/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5903e-05 - accuracy: 1.0000 - val_loss: 4.1710 - val_accuracy: 0.7154\n",
            "Epoch 344/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5922e-05 - accuracy: 1.0000 - val_loss: 4.1710 - val_accuracy: 0.7154\n",
            "Epoch 345/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5912e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 346/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5901e-05 - accuracy: 1.0000 - val_loss: 4.1710 - val_accuracy: 0.7154\n",
            "Epoch 347/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5894e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 348/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5902e-05 - accuracy: 1.0000 - val_loss: 4.1710 - val_accuracy: 0.7154\n",
            "Epoch 349/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5893e-05 - accuracy: 1.0000 - val_loss: 4.1710 - val_accuracy: 0.7154\n",
            "Epoch 350/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5894e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 351/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5891e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 352/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5897e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 353/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5890e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 354/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5883e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 355/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5887e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 356/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5882e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 357/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5874e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 358/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5876e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 359/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5880e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 360/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5873e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 361/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5868e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 362/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5865e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 363/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5870e-05 - accuracy: 1.0000 - val_loss: 4.1711 - val_accuracy: 0.7154\n",
            "Epoch 364/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5860e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 365/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5868e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 366/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5860e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 367/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5856e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 368/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5854e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 369/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5858e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 370/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5854e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 371/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5847e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 372/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5855e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 373/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5835e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 374/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5857e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 375/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5843e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 376/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5846e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 377/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5825e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 378/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5837e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 379/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5840e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 380/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5837e-05 - accuracy: 1.0000 - val_loss: 4.1712 - val_accuracy: 0.7154\n",
            "Epoch 381/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5835e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 382/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5839e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 383/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5836e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 384/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5821e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 385/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5821e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 386/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5813e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 387/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5814e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 388/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5821e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 389/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5812e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 390/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5810e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 391/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5814e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 392/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5811e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 393/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5821e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 394/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5802e-05 - accuracy: 1.0000 - val_loss: 4.1713 - val_accuracy: 0.7154\n",
            "Epoch 395/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5813e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 396/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5805e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 397/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5808e-05 - accuracy: 1.0000 - val_loss: 4.1715 - val_accuracy: 0.7154\n",
            "Epoch 398/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5807e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 399/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5795e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 400/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5803e-05 - accuracy: 1.0000 - val_loss: 4.1715 - val_accuracy: 0.7154\n",
            "Epoch 401/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5790e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 402/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5790e-05 - accuracy: 1.0000 - val_loss: 4.1715 - val_accuracy: 0.7154\n",
            "Epoch 403/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5791e-05 - accuracy: 1.0000 - val_loss: 4.1715 - val_accuracy: 0.7154\n",
            "Epoch 404/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5788e-05 - accuracy: 1.0000 - val_loss: 4.1714 - val_accuracy: 0.7154\n",
            "Epoch 405/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5787e-05 - accuracy: 1.0000 - val_loss: 4.1715 - val_accuracy: 0.7154\n",
            "Epoch 406/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5784e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 407/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5791e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 408/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5783e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 409/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5786e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 410/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5769e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 411/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5773e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 412/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5768e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 413/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5780e-05 - accuracy: 1.0000 - val_loss: 4.1715 - val_accuracy: 0.7154\n",
            "Epoch 414/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5787e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 415/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5778e-05 - accuracy: 1.0000 - val_loss: 4.1716 - val_accuracy: 0.7154\n",
            "Epoch 416/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5770e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 417/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5754e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 418/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5769e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 419/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5766e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 420/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5760e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 421/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5766e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 422/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5756e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 423/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5754e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 424/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5757e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 425/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5758e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 426/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5748e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 427/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5743e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 428/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5752e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 429/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5744e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 430/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5742e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 431/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5734e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 432/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5741e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 433/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5732e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 434/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5728e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 435/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5734e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 436/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5732e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 437/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5760e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 438/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5725e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 439/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5727e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 440/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5718e-05 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.7154\n",
            "Epoch 441/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5722e-05 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.7154\n",
            "Epoch 442/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5723e-05 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.7154\n",
            "Epoch 443/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5711e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 444/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5713e-05 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.7154\n",
            "Epoch 445/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5711e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 446/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5705e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 447/650\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 7.5769e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 448/650\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 7.5750e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 449/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5722e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 450/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5711e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 451/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5803e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 452/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5791e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 453/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5764e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 454/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5748e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 455/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5734e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 456/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5715e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 457/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5699e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 458/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5687e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 459/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5681e-05 - accuracy: 1.0000 - val_loss: 4.1717 - val_accuracy: 0.7154\n",
            "Epoch 460/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5690e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 461/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5684e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 462/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5678e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 463/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5682e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 464/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5680e-05 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.7154\n",
            "Epoch 465/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5677e-05 - accuracy: 1.0000 - val_loss: 4.1718 - val_accuracy: 0.7154\n",
            "Epoch 466/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5676e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 467/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5663e-05 - accuracy: 1.0000 - val_loss: 4.1719 - val_accuracy: 0.7154\n",
            "Epoch 468/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5668e-05 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.7154\n",
            "Epoch 469/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5668e-05 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.7154\n",
            "Epoch 470/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5661e-05 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.7154\n",
            "Epoch 471/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5657e-05 - accuracy: 1.0000 - val_loss: 4.1721 - val_accuracy: 0.7154\n",
            "Epoch 472/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5659e-05 - accuracy: 1.0000 - val_loss: 4.1721 - val_accuracy: 0.7154\n",
            "Epoch 473/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5655e-05 - accuracy: 1.0000 - val_loss: 4.1721 - val_accuracy: 0.7154\n",
            "Epoch 474/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5661e-05 - accuracy: 1.0000 - val_loss: 4.1721 - val_accuracy: 0.7154\n",
            "Epoch 475/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5649e-05 - accuracy: 1.0000 - val_loss: 4.1721 - val_accuracy: 0.7154\n",
            "Epoch 476/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5651e-05 - accuracy: 1.0000 - val_loss: 4.1722 - val_accuracy: 0.7154\n",
            "Epoch 477/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5649e-05 - accuracy: 1.0000 - val_loss: 4.1722 - val_accuracy: 0.7154\n",
            "Epoch 478/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5656e-05 - accuracy: 1.0000 - val_loss: 4.1722 - val_accuracy: 0.7154\n",
            "Epoch 479/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5639e-05 - accuracy: 1.0000 - val_loss: 4.1722 - val_accuracy: 0.7154\n",
            "Epoch 480/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5645e-05 - accuracy: 1.0000 - val_loss: 4.1722 - val_accuracy: 0.7154\n",
            "Epoch 481/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5640e-05 - accuracy: 1.0000 - val_loss: 4.1723 - val_accuracy: 0.7154\n",
            "Epoch 482/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5645e-05 - accuracy: 1.0000 - val_loss: 4.1722 - val_accuracy: 0.7154\n",
            "Epoch 483/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5639e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 484/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5645e-05 - accuracy: 1.0000 - val_loss: 4.1726 - val_accuracy: 0.7154\n",
            "Epoch 485/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5644e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 486/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5631e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 487/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5629e-05 - accuracy: 1.0000 - val_loss: 4.1726 - val_accuracy: 0.7154\n",
            "Epoch 488/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5626e-05 - accuracy: 1.0000 - val_loss: 4.1726 - val_accuracy: 0.7154\n",
            "Epoch 489/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5624e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 490/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5623e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 491/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5618e-05 - accuracy: 1.0000 - val_loss: 4.1723 - val_accuracy: 0.7154\n",
            "Epoch 492/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5654e-05 - accuracy: 1.0000 - val_loss: 4.1723 - val_accuracy: 0.7154\n",
            "Epoch 493/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5638e-05 - accuracy: 1.0000 - val_loss: 4.1724 - val_accuracy: 0.7154\n",
            "Epoch 494/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5619e-05 - accuracy: 1.0000 - val_loss: 4.1724 - val_accuracy: 0.7154\n",
            "Epoch 495/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5618e-05 - accuracy: 1.0000 - val_loss: 4.1726 - val_accuracy: 0.7154\n",
            "Epoch 496/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5613e-05 - accuracy: 1.0000 - val_loss: 4.1726 - val_accuracy: 0.7154\n",
            "Epoch 497/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5616e-05 - accuracy: 1.0000 - val_loss: 4.1725 - val_accuracy: 0.7154\n",
            "Epoch 498/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5628e-05 - accuracy: 1.0000 - val_loss: 4.1726 - val_accuracy: 0.7154\n",
            "Epoch 499/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5616e-05 - accuracy: 1.0000 - val_loss: 4.1726 - val_accuracy: 0.7154\n",
            "Epoch 500/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5616e-05 - accuracy: 1.0000 - val_loss: 4.1726 - val_accuracy: 0.7154\n",
            "Epoch 501/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5610e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 502/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5604e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 503/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5603e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 504/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5600e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 505/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5590e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 506/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5597e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 507/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5595e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 508/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5591e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 509/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5586e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 510/650\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 7.5590e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 511/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5590e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 512/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5588e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 513/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5591e-05 - accuracy: 1.0000 - val_loss: 4.1727 - val_accuracy: 0.7154\n",
            "Epoch 514/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5576e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 515/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5572e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 516/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5566e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 517/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5566e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 518/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5566e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 519/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5576e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 520/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5569e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 521/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5552e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 522/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5567e-05 - accuracy: 1.0000 - val_loss: 4.1728 - val_accuracy: 0.7154\n",
            "Epoch 523/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5560e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 524/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5559e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 525/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5554e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 526/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5551e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 527/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5557e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 528/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5541e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 529/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5542e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 530/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5556e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 531/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5540e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 532/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5560e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 533/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5530e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 534/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5550e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 535/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5530e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 536/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5543e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 537/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5531e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 538/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5529e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 539/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5530e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 540/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5521e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 541/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5519e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 542/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5528e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 543/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5517e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 544/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5521e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 545/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5525e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 546/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5521e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 547/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5510e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 548/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5634e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 549/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5600e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 550/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5582e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 551/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5560e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 552/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5542e-05 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.7154\n",
            "Epoch 553/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5523e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 554/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5516e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 555/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5512e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 556/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5506e-05 - accuracy: 1.0000 - val_loss: 4.1730 - val_accuracy: 0.7154\n",
            "Epoch 557/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5504e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 558/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5500e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 559/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5491e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 560/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5501e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 561/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5488e-05 - accuracy: 1.0000 - val_loss: 4.1731 - val_accuracy: 0.7154\n",
            "Epoch 562/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5484e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 563/650\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 7.5489e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 564/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5487e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 565/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5489e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 566/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5474e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 567/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5485e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 568/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5474e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 569/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5470e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 570/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5477e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 571/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5466e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.7154\n",
            "Epoch 572/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5469e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 573/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5473e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 574/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5465e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 575/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5460e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 576/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5459e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 577/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5456e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 578/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5450e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 579/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5453e-05 - accuracy: 1.0000 - val_loss: 4.1734 - val_accuracy: 0.7154\n",
            "Epoch 580/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5439e-05 - accuracy: 1.0000 - val_loss: 4.1733 - val_accuracy: 0.7154\n",
            "Epoch 581/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5446e-05 - accuracy: 1.0000 - val_loss: 4.1734 - val_accuracy: 0.7154\n",
            "Epoch 582/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5455e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 583/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5441e-05 - accuracy: 1.0000 - val_loss: 4.1734 - val_accuracy: 0.7154\n",
            "Epoch 584/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5445e-05 - accuracy: 1.0000 - val_loss: 4.1734 - val_accuracy: 0.7154\n",
            "Epoch 585/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5446e-05 - accuracy: 1.0000 - val_loss: 4.1734 - val_accuracy: 0.7154\n",
            "Epoch 586/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5434e-05 - accuracy: 1.0000 - val_loss: 4.1734 - val_accuracy: 0.7154\n",
            "Epoch 587/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5443e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 588/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5441e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 589/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5433e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 590/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5433e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 591/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5431e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 592/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5424e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 593/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5434e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 594/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5423e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 595/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5421e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 596/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5411e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 597/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5421e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 598/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5414e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 599/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5405e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 600/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5452e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 601/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5413e-05 - accuracy: 1.0000 - val_loss: 4.1735 - val_accuracy: 0.7154\n",
            "Epoch 602/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5416e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 603/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5410e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 604/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5407e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 605/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5396e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 606/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5403e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 607/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5403e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 608/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5405e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 609/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5394e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 610/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5402e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 611/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5383e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 612/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5389e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 613/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5382e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 614/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5385e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 615/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5388e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 616/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5429e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 617/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5415e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 618/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5393e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 619/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5386e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 620/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5384e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 621/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5375e-05 - accuracy: 1.0000 - val_loss: 4.1736 - val_accuracy: 0.7154\n",
            "Epoch 622/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5388e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 623/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5375e-05 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.7154\n",
            "Epoch 624/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5371e-05 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.7154\n",
            "Epoch 625/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5373e-05 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.7154\n",
            "Epoch 626/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5372e-05 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.7154\n",
            "Epoch 627/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5382e-05 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.7154\n",
            "Epoch 628/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5369e-05 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.7154\n",
            "Epoch 629/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5356e-05 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.7154\n",
            "Epoch 630/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5358e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 631/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5357e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 632/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5344e-05 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.7154\n",
            "Epoch 633/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5347e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 634/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5354e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 635/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5332e-05 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.7154\n",
            "Epoch 636/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5354e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 637/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5336e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 638/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5351e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 639/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5346e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 640/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5334e-05 - accuracy: 1.0000 - val_loss: 4.1739 - val_accuracy: 0.7154\n",
            "Epoch 641/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5336e-05 - accuracy: 1.0000 - val_loss: 4.1740 - val_accuracy: 0.7154\n",
            "Epoch 642/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5339e-05 - accuracy: 1.0000 - val_loss: 4.1740 - val_accuracy: 0.7154\n",
            "Epoch 643/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5331e-05 - accuracy: 1.0000 - val_loss: 4.1741 - val_accuracy: 0.7154\n",
            "Epoch 644/650\n",
            "71/71 [==============================] - 0s 2ms/step - loss: 7.5322e-05 - accuracy: 1.0000 - val_loss: 4.1740 - val_accuracy: 0.7154\n",
            "Epoch 645/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5335e-05 - accuracy: 1.0000 - val_loss: 4.1741 - val_accuracy: 0.7154\n",
            "Epoch 646/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5320e-05 - accuracy: 1.0000 - val_loss: 4.1741 - val_accuracy: 0.7154\n",
            "Epoch 647/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5328e-05 - accuracy: 1.0000 - val_loss: 4.1740 - val_accuracy: 0.7154\n",
            "Epoch 648/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5327e-05 - accuracy: 1.0000 - val_loss: 4.1740 - val_accuracy: 0.7154\n",
            "Epoch 649/650\n",
            "71/71 [==============================] - 0s 3ms/step - loss: 7.5322e-05 - accuracy: 1.0000 - val_loss: 4.1741 - val_accuracy: 0.7154\n",
            "Epoch 650/650\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 7.5322e-05 - accuracy: 1.0000 - val_loss: 4.1741 - val_accuracy: 0.7154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "0884a752-4ae6-4ee8-c893-9f881953f316"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "e396b2d0-1466-4671-d504-3fdfbaf3c03b"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0562 - accuracy: 0.7208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "eed97bc1-d1cd-4fa5-f3e2-518eb00ee095"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5125998 , 0.48740014]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "2676fb72-cbd9-47a7-d037-de57ebaaf57a"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}